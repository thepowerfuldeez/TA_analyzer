{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-10T13:17:44.253064",
     "start_time": "2016-12-10T13:17:43.843903"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import vk_api\n",
    "vk_session = vk_api.VkApi(token=\"4ee251bf489b9d88106f08b36239eb0ab39bed07ca3fb9adacf62346cb2981eed59a26f4c29a18123f053\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vk_session.authorization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cached_ids = pickle.load(open(\"cache.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-10T13:17:47.866954",
     "start_time": "2016-12-10T13:17:47.849288"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_many_of_public(group_link, vk_session):\n",
    "    global cached_ids\n",
    "    \n",
    "    shortname = group_link[group_link.rfind(\"/\")+1:]\n",
    "    r = vk_session.method(\"groups.getById\", {\"group_ids\": shortname})\n",
    "    group_id = r[0][\"id\"]\n",
    "    \n",
    "    if group_id not in cached_ids.keys():\n",
    "    \n",
    "        \"\"\"Все сообщества подписчиков сообщества\"\"\"\n",
    "        users = vk_api.VkTools(vk_session).get_all(\"groups.getMembers\", 100, {'group_id':group_id})['items']\n",
    "        k = int(len(users) / 1000)\n",
    "        if k:\n",
    "            users = users[::k]\n",
    "\n",
    "        data_for_clustering = []\n",
    "        users_publicpages = []\n",
    "        with vk_api.VkRequestsPool(vk_session) as pool:\n",
    "            \n",
    "            for i in range(0, len(users), 1000):\n",
    "                batch = users[i:i+1000]\n",
    "                data_for_clustering.append(pool.method('users.get', {\n",
    "                        \"user_ids\": batch,\n",
    "                        \"fields\": \"sex,age,education,universities,schools,interests,music,movies,bdate,city,country\"\n",
    "                    }))\n",
    "\n",
    "                for user_id in batch:\n",
    "                    users_publicpages.append(pool.method('users.getSubscriptions', {\n",
    "                                \"user_id\": user_id\n",
    "                            }))\n",
    "\n",
    "        data_for_clustering = [x for x in [x.result for x in data_for_clustering]]\n",
    "        t = []\n",
    "        for user in users_publicpages:\n",
    "            try:\n",
    "                t.append(user.result['groups']['items'])\n",
    "            except:\n",
    "                pass\n",
    "        users_publicpages = t\n",
    "        \n",
    "        wall50 = vk_session.method(\"wall.get\", {\"owner_id\": -group_id, \"filter\": \"owner\", \"count\": 100})['items'][::2]\n",
    "        \n",
    "        result = data_for_clustering, users_publicpages, wall50\n",
    "        cached_ids[group_id] = result\n",
    "        pickle.dump(cached_ids, open(\"cache.p\", \"wb\"))\n",
    "        return \n",
    "    else:\n",
    "        return cached_ids[group_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-10T13:17:52.251995",
     "start_time": "2016-12-10T13:17:49.852908"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "t = time()\n",
    "a = get_many_of_public(\"https://vk.com/goto_msk\", vk_session)\n",
    "print(time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(cached_ids[80270762][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cached_ids = pickle.load(open(\"cache.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cached_ids.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"communities.csv\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexer = pickle.load(open(\"community_indexer.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexer = {v: k for k, v in data[\"link\"].items()}\n",
    "y = {}\n",
    "for group_link in list(indexer.keys())[1:]:\n",
    "    shortname = group_link[group_link.rfind(\"/\")+1:]\n",
    "    if \"public\" in shortname:\n",
    "        shortname = shortname[6:]\n",
    "    y[shortname] = indexer[group_link]\n",
    "indexer = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import vk\n",
    "session = vk.Session()\n",
    "api = vk.API(session)\n",
    "\n",
    "x = {}\n",
    "for k, v in indexer.items():\n",
    "    try:\n",
    "        r = api.groups.getById(group_ids=k)\n",
    "        group_id = r[0][\"gid\"]\n",
    "        print(group_id)\n",
    "        x[group_id] = v\n",
    "    except:\n",
    "        pass\n",
    "indexer = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for gid in tqdm_notebook(cached_ids):\n",
    "    try:\n",
    "        y = data[\"category\"][indexer[gid]]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    x_0 = []\n",
    "    try:\n",
    "        for i in range(1000):\n",
    "            x = cached_ids[gid][0][0][i]\n",
    "            try:\n",
    "                ci = x[\"city\"][\"id\"]\n",
    "            except:\n",
    "                ci = 0\n",
    "            try:\n",
    "                u = x[\"universities\"][0][\"id\"]\n",
    "            except:\n",
    "                u = 0\n",
    "            try:\n",
    "                s = x[\"schools\"][0][\"id\"]\n",
    "            except:\n",
    "                s = 0\n",
    "            try:\n",
    "                bd = x[\"bdate\"]\n",
    "                if len(bd.split(\".\")) == 3:\n",
    "                    age = 2014 - int(bd.split(\".\")[2])\n",
    "            except:\n",
    "                age = 0\n",
    "            x_0.append(np.array([x.get(\"sex\", 0), ci, u, s, age], dtype=\"int32\"))\n",
    "        z_0 = []\n",
    "        try:\n",
    "            for j in range(50):\n",
    "                wall_post = cached_ids[gid][2][j]\n",
    "                has_photo, has_text, has_audio = 0, 0, 0\n",
    "                if wall_post.get(\"text\"):\n",
    "                    has_text = 1\n",
    "                t = wall_post.get(\"attachments\")\n",
    "                if t:\n",
    "                    for a in t:\n",
    "                        if a.get(\"type\") == \"audio\":\n",
    "                            has_audio = 1\n",
    "                        if a.get(\"type\") == \"photo\":\n",
    "                            has_photo = 1\n",
    "                z_0.append([has_text, has_photo, has_audio])\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            \n",
    "        t_sex = [z[0] for z in x_0]\n",
    "        f1 = t_sex.count(2) / len(t_sex)\n",
    "        f2 = t_sex.count(1) / len(t_sex)\n",
    "        f3 = Counter([z[1] for z in x_0 if z[1]]).most_common(1)[0][0]\n",
    "        f4 = Counter([z[2] for z in x_0 if z[2]]).most_common(1)[0][0]\n",
    "        f5 = Counter([z[3] for z in x_0 if z[3]]).most_common(1)[0][0]\n",
    "        f6_10 = [t[0] for t in Counter([item for sublist in cached_ids[gid][1] for item in sublist]).most_common(5)]\n",
    "        try:\n",
    "            f11 = sum([z[0] for z in z_0]) / len(z_0)\n",
    "        except:\n",
    "            f11 = 0\n",
    "        try:\n",
    "            f12 = sum([z[1] for z in z_0]) / len(z_0)\n",
    "        except:\n",
    "            f12 = 0\n",
    "        try:\n",
    "            f13 = sum([z[2] for z in z_0]) / len(z_0)\n",
    "        except:\n",
    "            f13 = 0\n",
    "        ages = [z[4] for z in x_0 if z[4]]\n",
    "        f14 = np.median(ages)\n",
    "        x_1 = [f1, f2, f3, f4, f5, *f6_10, f11, f12, f13, f14]\n",
    "        print(gid, x_1)\n",
    "        \n",
    "        X.append(np.array(x_1, dtype=\"float32\"))\n",
    "        Y.append(y)\n",
    "    except IndexError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_cache(gid):\n",
    "    x_0 = []\n",
    "    try:\n",
    "        for i in range(1000):\n",
    "            x = cached_ids[gid][0][0][i]\n",
    "            try:\n",
    "                ci = x[\"city\"][\"id\"]\n",
    "            except:\n",
    "                ci = 0\n",
    "            try:\n",
    "                u = x[\"universities\"][0][\"id\"]\n",
    "            except:\n",
    "                u = 0\n",
    "            try:\n",
    "                s = x[\"schools\"][0][\"id\"]\n",
    "            except:\n",
    "                s = 0\n",
    "            try:\n",
    "                bd = x[\"bdate\"]\n",
    "                if len(bd.split(\".\")) == 3:\n",
    "                    age = 2014 - int(bd.split(\".\")[2])\n",
    "            except:\n",
    "                age = 0\n",
    "            x_0.append(np.array([x.get(\"sex\", 0), ci, u, s, age], dtype=\"int32\"))\n",
    "        z_0 = []\n",
    "        try:\n",
    "            for j in range(50):\n",
    "                wall_post = cached_ids[gid][2][j]\n",
    "                has_photo, has_text, has_audio = 0, 0, 0\n",
    "                if wall_post.get(\"text\"):\n",
    "                    has_text = 1\n",
    "                t = wall_post.get(\"attachments\")\n",
    "                if t:\n",
    "                    for a in t:\n",
    "                        if a.get(\"type\") == \"audio\":\n",
    "                            has_audio = 1\n",
    "                        if a.get(\"type\") == \"photo\":\n",
    "                            has_photo = 1\n",
    "                z_0.append([has_text, has_photo, has_audio])\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            \n",
    "        t_sex = [z[0] for z in x_0]\n",
    "        f1 = t_sex.count(2) / len(t_sex)\n",
    "        f2 = t_sex.count(1) / len(t_sex)\n",
    "        f3 = Counter([z[1] for z in x_0 if z[1]]).most_common(1)[0][0]\n",
    "        f4 = Counter([z[2] for z in x_0 if z[2]]).most_common(1)[0][0]\n",
    "        f5 = Counter([z[3] for z in x_0 if z[3]]).most_common(1)[0][0]\n",
    "#         f6_10 = [t[0] for t in Counter([item for sublist in cached_ids[gid][1] for item in sublist]).most_common(5)]\n",
    "        f6_10 = [0, 0, 0, 0, 0]\n",
    "        try:\n",
    "            f11 = sum([z[0] for z in z_0]) / len(z_0)\n",
    "        except:\n",
    "            f11 = 0\n",
    "        try:\n",
    "            f12 = sum([z[1] for z in z_0]) / len(z_0)\n",
    "        except:\n",
    "            f12 = 0\n",
    "        try:\n",
    "            f13 = sum([z[2] for z in z_0]) / len(z_0)\n",
    "        except:\n",
    "            f13 = 0\n",
    "        ages = [z[4] for z in x_0 if z[4]]\n",
    "        f14 = np.median(ages)\n",
    "        x_1 = [f1, f2, f3, f4, f5, *f6_10, f11, f12, f13, f14]\n",
    "        \n",
    "        return np.array(x_1, dtype=\"float32\")\n",
    "    except IndexError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "b144c593e1c74cf68e516fa56c47fb2d": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
